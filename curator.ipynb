{"cells":[{"cell_type":"markdown","source":"# Domain Name Curator\n\nThe natural language component of <i>IntelliSearch</i>, which uses both the spaCY and NLTK libraries to help sort through the millions of domain names produced by the previous two components and come up with a word association network that connects all the names by assigning association strength values between them (more on this later).\n\nThis section can be further broken down into 3 subsections:\n- Using NLTK POS tagger to classify existing words into specific categories\n- Building a word association network with spaCY\n- Using the NLTK library to find synonyms for a given word\n\n## Using NLTK POS tagger to classify existing words into specific categories\n","metadata":{"tags":[],"cell_id":"00000-5fac9cfd-3afa-43bf-b2b6-f7b5c1cc7197","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-d7cbd315-57c4-43cb-9243-b24cfa12a9e8","output_cleared":false,"source_hash":"96307baf","execution_start":1607745249070,"execution_millis":5673,"deepnote_cell_type":"code"},"source":"!pip install nltk","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting nltk\n  Downloading nltk-3.5.zip (1.4 MB)\n\u001b[K     |████████████████████████████████| 1.4 MB 11.0 MB/s \n\u001b[?25hCollecting click\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n\u001b[K     |████████████████████████████████| 82 kB 2.5 MB/s \n\u001b[?25hRequirement already satisfied: joblib in /opt/venv/lib/python3.7/site-packages (from nltk) (0.17.0)\nCollecting regex\n  Downloading regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719 kB)\n\u001b[K     |████████████████████████████████| 719 kB 40.1 MB/s \n\u001b[?25hRequirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (from nltk) (4.54.1)\nBuilding wheels for collected packages: nltk\n  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434676 sha256=c37c2abc74da890133af6503e9767bc183ec1994c8cd59b7520ddb60eb521171\n  Stored in directory: /home/jovyan/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\nSuccessfully built nltk\nInstalling collected packages: click, regex, nltk\nSuccessfully installed click-7.1.2 nltk-3.5 regex-2020.11.13\n\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-90fd2d83-db50-472c-81ee-69d2439185c8","output_cleared":false,"source_hash":"629e6c8d","execution_millis":1179,"execution_start":1607745254752,"deepnote_cell_type":"code"},"source":"import nltk\nnltk.download('brown')\nnltk.download('universal_tagset')","execution_count":null,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/brown.zip.\n[nltk_data] Downloading package universal_tagset to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Unzipping taggers/universal_tagset.zip.\n","output_type":"stream"},{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-b254aa3e-a067-4e33-9981-ec8c7e9b610d","output_cleared":false,"source_hash":"4046afa0","execution_start":1607745258584,"execution_millis":8419,"deepnote_cell_type":"code"},"source":"wordtags = nltk.ConditionalFreqDist((w.lower(), t) for w, t in nltk.corpus.brown.tagged_words(tagset=\"universal\"))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-cb1a4ca0-b7aa-4f7f-9ba1-8c71a3a9d996","output_cleared":false,"source_hash":"7080ac95","execution_start":1607745301862,"execution_millis":0,"deepnote_cell_type":"code"},"source":"def getCategory(word):\n    categories = list(wordtags[word])\n    category_map = {\n        'NOUN': 'nouns',\n        'VERB': 'verbs',\n        'ADJ': 'adjectives',\n        'ADV': 'adverbs',\n        'ADP': 'adpositions',\n        'PRON': 'pronouns',\n        'CONJ': 'conjunctinos',\n        'DET': 'determiners',\n        'NUM': 'numbers',\n        'PRT': 'particles',\n        'X': 'other'\n    }\n    if len(categories) == 0:\n        return ['other']\n    \n    normalized_cats = []\n    for cat in categories:\n        normalized_cats.append(category_map[cat])\n    return normalized_cats","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00005-e9097e40-780c-4a00-bc84-21c8617b9019","output_cleared":false,"source_hash":"6e44562f","execution_millis":5,"execution_start":1607745411821,"deepnote_cell_type":"code"},"source":"words = ['apple', 'apply', 'beautiful', 'funny', 'joke', 'happy']\n\nfor word in words:\n    print(word, getCategory(word))","execution_count":null,"outputs":[{"name":"stdout","text":"apple ['nouns']\napply ['verbs']\nbeautiful ['adjectives']\nfunny ['adjectives', 'adverbs']\njoke ['nouns', 'verbs']\nhappy ['adjectives', 'nouns']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building a word association network with spaCY","metadata":{"tags":[],"cell_id":"00003-8352d54b-f280-4a81-8fac-b8254fddaa88","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-4d416eda-aae7-457c-a1bf-0c777e436762","output_cleared":false,"source_hash":"d54a86b7","execution_millis":5135,"execution_start":1607738910478,"deepnote_cell_type":"code"},"source":"!pip install spacy\n!python -m spacy download en_core_web_lg","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /opt/venv/lib/python3.7/site-packages (2.3.5)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/venv/lib/python3.7/site-packages (from spacy) (1.0.0)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/venv/lib/python3.7/site-packages (from spacy) (2.25.0)\nRequirement already satisfied: numpy>=1.15.0 in /opt/venv/lib/python3.7/site-packages (from spacy) (1.19.4)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/venv/lib/python3.7/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/venv/lib/python3.7/site-packages (from spacy) (4.54.1)\nRequirement already satisfied: setuptools in /opt/venv/lib/python3.7/site-packages (from spacy) (50.3.2)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/venv/lib/python3.7/site-packages (from spacy) (0.8.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from spacy) (3.0.5)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/venv/lib/python3.7/site-packages (from spacy) (0.7.4)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/venv/lib/python3.7/site-packages (from spacy) (2.0.5)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/venv/lib/python3.7/site-packages (from spacy) (1.1.3)\nRequirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/venv/lib/python3.7/site-packages (from spacy) (7.4.5)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/venv/lib/python3.7/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.2)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.11.8)\nRequirement already satisfied: zipp>=0.5 in /opt/venv/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: en_core_web_lg==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz#egg=en_core_web_lg==2.3.1 in /opt/venv/lib/python3.7/site-packages (2.3.1)\nRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/venv/lib/python3.7/site-packages (from en_core_web_lg==2.3.1) (2.3.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.5)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\nRequirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.5)\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.5)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.54.1)\nRequirement already satisfied: numpy>=1.15.0 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.19.4)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.25.0)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.8.0)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.7.4)\nRequirement already satisfied: setuptools in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (50.3.2)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.5)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/venv/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.5)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.26.2)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2020.11.8)\nRequirement already satisfied: zipp>=0.5 in /opt/venv/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.4.0)\n\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the model via spacy.load('en_core_web_lg')\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-5872883f-cc14-4905-b22a-1c2e55a1ccba","output_cleared":false,"source_hash":"1ba1837a","execution_millis":7303,"execution_start":1607739009581,"deepnote_cell_type":"code"},"source":"import csv\nimport spacy\nimport en_core_web_lg\n\nnlp = en_core_web_lg.load()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-577c874d-c2d3-4f12-ac4d-3a47e2ba8866","output_cleared":false,"source_hash":"16dc7383","execution_millis":25,"execution_start":1607746473280,"deepnote_cell_type":"code"},"source":"tokens = nlp('great steve fantastic watson') \n  \nfor token in tokens: \n    '''\n    Attributes\n    - text: the word string, \n    - has_vector: if it contains a vector representation in the model,  \n    - vector_norm: the algebraic norm of the vector, \n    - is_oov: if the word is out of vocabulary. \n    '''\n    print(token.text, token.has_vector, token.vector_norm, token.is_oov) \n\ntoken1, token2, token3, token4 = tokens[0], tokens[1], tokens[2], tokens[3]\n  \nprint(\"Similarity:\", token1, token2, token1.similarity(token2)) \nprint(\"Similarity:\", token1, token3, token1.similarity(token3)) \nprint(\"Similarity:\", token1, token4, token1.similarity(token4)) \nprint(\"Similarity:\", token2, token3, token2.similarity(token3)) \nprint(\"Similarity:\", token2, token4, token2.similarity(token4)) \nprint(\"Similarity:\", token3, token4, token3.similarity(token4)) ","execution_count":null,"outputs":[{"name":"stdout","text":"great True 5.4395933 False\nsteve True 6.181552 False\nfantastic True 5.561246 False\nwatson True 6.6602826 False\nSimilarity: great steve 0.21640417\nSimilarity: great fantastic 0.81248736\nSimilarity: great watson 0.07907305\nSimilarity: steve fantastic 0.16961657\nSimilarity: steve watson 0.4813081\nSimilarity: fantastic watson 0.05662866\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-163ff29b-b5ca-451f-8e40-c30fedd53e72","output_cleared":false,"source_hash":"f280b405","execution_millis":0,"execution_start":1607747253902,"deepnote_cell_type":"code"},"source":"category_list = [\"adjectives\", \"battleships\", \"nouns\", \"verbs\", \"predicates\", \"positive\", \"tech\", \"places\", \"names\", \"gods\", \"stars\", \"collections\"]\n\nword_list = {}\n\nfor category in category_list:\n    \n    txt_file = \"datasets/word-files/\"+category+\".txt\"\n    \n    with open(txt_file, 'r+') as f:\n        for word in f.read().splitlines():\n            if category == 'other':\n                categories = getCategory(word)\n                categories.append(category)\n                categories = list(dict.fromkeys(categories))\n                word_list[word.lower().strip()] = {'category': categories, 'similarity': []}\n            else:\n                try:\n                    word_list[word.lower().strip()]['category'].append(category)\n                except:\n                    word_list[word.lower().strip()] = {'category': [category], 'similarity': []}\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00011-8e7db4db-72cf-4641-8529-2ffc72e2d0ea","output_cleared":false,"source_hash":"2d16838","execution_millis":2942,"execution_start":1607747254801,"deepnote_cell_type":"code"},"source":"# getting all the keys of the dictionary\nall_words = [word for word in word_list.keys()]\n\n# some words get split for no reason, gotta remove them from list\ncount = 0\nsplitted_words = []\nfor idx, word in enumerate(all_words):\n    if word != str(tokens[idx+count]):\n        splitted_words.append(word)\n        count += 1\nprint(count, splitted_words)\nfor word in splitted_words:\n    all_words.remove(word)\n\n# tokenizing all the words\ntokens = nlp(' '.join(all_words))","execution_count":null,"outputs":[{"name":"stdout","text":"10 ['so-called', 'optional', 'cant', 'long-term', 'kidney', 'wed', 'gonna', \"don't\", 'gotta', \"won't\"]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00012-816eae4d-2716-4d67-87fb-c03f16f58628","output_cleared":false,"source_hash":"8d843ec0","execution_millis":13,"execution_start":1607747260009,"deepnote_cell_type":"code"},"source":"# Makeshift priority queue function that would take the newest tuple, \n# compare it to the existing list of tuples, and if it's bigger than the smallest\n# tuple in the list, bump that tuple out and append this new tuple to the list\n# Then, sort the list and return\n\ndef addToList(ele, lst, num_ele):\n    if ele in lst:\n        return lst\n    if len(lst) >= num_ele: #if list is at capacity\n        if ele[1] > float(lst[-1][1]): #if element's sig_score is larger than smallest sig_score in list\n            lst.pop(-1)\n            lst.append((ele[0], str(ele[1])))\n            lst.sort(key = lambda x: float(x[1]), reverse=True)\n    else:\n        lst.append((ele[0], str(ele[1])))\n        lst.sort(key = lambda x: float(x[1]), reverse=True)\n    return lst","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00013-34de8130-6af9-4748-8d87-5dd10facb699","output_cleared":true,"source_hash":null,"execution_millis":10041,"execution_start":1607747274498,"deepnote_cell_type":"code"},"source":"# Nested for loop to tokenize all words\n# Note: This takes quite a long time to run (~8 hours, if not more)\n\nfor i in range(len(all_words)):\n    for j in range(i, len(all_words)):\n        prev_list_i = word_list[str(tokens[i])]['similarity']\n        word_list[str(tokens[i])]['similarity'] = addToList((str(tokens[j]), tokens[i].similarity(tokens[j])), prev_list_i, 100)\n        prev_list_j = word_list[str(tokens[j])]['similarity']\n        word_list[str(tokens[j])]['similarity'] = addToList((str(tokens[i]), tokens[i].similarity(tokens[j])), prev_list_j, 100)\n        \n    print('Done with ', all_words[i])","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using the NLTK library to find synonyms for a given word","metadata":{"tags":[],"cell_id":"00014-9b33d6c8-726a-4910-b612-f2cad5fd66e1","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00015-00ce09c7-0856-4ca6-a90c-3515ab218a6c","output_cleared":false,"source_hash":"2b0d0c48","execution_start":1607747765506,"execution_millis":462,"deepnote_cell_type":"code"},"source":"nltk.download('wordnet')","execution_count":null,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\n","output_type":"stream"},{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00014-818e5673-bdc9-4e56-a8c7-ed11876e1722","output_cleared":false,"source_hash":"2e01e627","execution_millis":3,"execution_start":1607747813159,"deepnote_cell_type":"code"},"source":"from nltk.corpus import wordnet \n  \ndef find_synonyms(word):\n    synonyms = [] \n    forbidden_chars = ['0','1','2','3','4','5','6','7','8','9',' ',':','(',')', '-', '#', '_']\n\n    for syn in wordnet.synsets(word): \n        for l in syn.lemmas(): \n            if all(char not in l.name() for char in forbidden_chars) and l.name() not in synonyms:\n                synonyms.append(l.name().lower()) \n    \n    if len(synonyms) == 1 and synonyms[0].lower() == word:\n        return []\n    return synonyms","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00016-47be1b55-6d63-4d78-a4fb-f5249483b063","output_cleared":false,"source_hash":"1aeae379","execution_millis":8,"execution_start":1607747816612,"deepnote_cell_type":"code"},"source":"find_synonyms('funny')","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":66,"data":{"text/plain":"['funny',\n 'amusing',\n 'comic',\n 'comical',\n 'laughable',\n 'mirthful',\n 'risible',\n 'curious',\n 'odd',\n 'peculiar',\n 'queer',\n 'rum',\n 'rummy',\n 'singular',\n 'fishy',\n 'shady',\n 'suspect',\n 'suspicious']"},"metadata":{}}]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"a46b06e3-ecb4-46f0-8887-5d66e9796e86","deepnote_execution_queue":[]}}